"""
æ•°æ®å¤„ç†å™¨
Data Processor Module
"""

from typing import Union, List, Dict, Any, Tuple, Optional
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split


class DataProcessor:
    """MOFæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            config: å¤„ç†é…ç½®
        """
        self.config = config or {}
        self.scaler = None
        self.feature_names = []
    
    def extract_features_from_mofid(
        self,
        data: Union[List[Dict], pd.DataFrame],
        target_property: str = None
    ) -> Tuple[pd.DataFrame, Optional[pd.Series]]:
        """
        ä»MOFidæ•°æ®ä¸­æå–ç‰¹å¾
        
        Args:
            data: MOFidæ•°æ®
            target_property: ç›®æ ‡å±æ€§åç§°
            
        Returns:
            (ç‰¹å¾DataFrame, ç›®æ ‡Series)å…ƒç»„
        """
        if isinstance(data, list):
            df = pd.json_normalize(data)
        else:
            df = data.copy()
        
        # æå–MOFidç›¸å…³ç‰¹å¾
        feature_columns = []
        
        # åŸºç¡€ä¿¡æ¯ç‰¹å¾
        if 'info.natoms' in df.columns:
            feature_columns.append('info.natoms')
        if 'info.pld' in df.columns:
            feature_columns.append('info.pld')
        if 'info.lcd' in df.columns:
            feature_columns.append('info.lcd')
        if 'info.density' in df.columns:
            feature_columns.append('info.density')
        
        # MOFidæ–‡æœ¬ç‰¹å¾ï¼ˆéœ€è¦è¿›ä¸€æ­¥å¤„ç†ï¼‰
        mofid_cols = [col for col in df.columns if 'mofid' in col.lower()]
        
        # æå–æ•°å€¼ç‰¹å¾
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        feature_columns.extend([col for col in numeric_cols if col not in feature_columns])
        
        # è¿‡æ»¤æ‰ç›®æ ‡åˆ—
        if target_property:
            feature_columns = [col for col in feature_columns if col != target_property]
        
        X = df[feature_columns] if feature_columns else df
        y = df[target_property] if target_property and target_property in df.columns else None
        
        self.feature_names = list(X.columns)
        
        return X, y
    
    def extract_property_from_qmof(
        self,
        data: Union[List[Dict], pd.DataFrame],
        property_name: str,
        theory_level: str = 'pbe'
    ) -> Tuple[List[str], List[float]]:
        """
        ä»QMOFæ•°æ®ä¸­æå–æŒ‡å®šå±æ€§ï¼ˆæ”¯æŒä»»æ„åˆ—åï¼‰
        
        Args:
            data: QMOFæ•°æ®
            property_name: å±æ€§åç§°ï¼ˆå¯ä»¥æ˜¯å®Œæ•´çš„åˆ—åï¼Œå¦‚'outputs.pbe.bandgap'ï¼Œä¹Ÿå¯ä»¥æ˜¯ç®€çŸ­åç§°å¦‚'bandgap'ï¼‰
            theory_level: ç†è®ºæ°´å¹³ï¼ˆ'pbe', 'hle17', 'hse06'ç­‰ï¼‰- ä»…åœ¨ä½¿ç”¨ç®€çŸ­åç§°æ—¶æœ‰æ•ˆ
            
        Returns:
            (MOF IDåˆ—è¡¨, å±æ€§å€¼åˆ—è¡¨)å…ƒç»„
        """
        ids = []
        values = []
        
        if isinstance(data, list):
            for entry in data:
                mof_id = entry.get('qmof_id', entry.get('name', 'unknown'))
                
                # å°è¯•ä»outputsä¸­æå–
                try:
                    if 'outputs' in entry and theory_level in entry['outputs']:
                        value = entry['outputs'][theory_level].get(property_name)
                        if value is not None:
                            ids.append(mof_id)
                            values.append(value)
                    # å°è¯•ç›´æ¥ä»infoä¸­æå–ï¼ˆå¦‚pld, lcdç­‰ï¼‰
                    elif 'info' in entry:
                        value = entry['info'].get(property_name)
                        if value is not None:
                            ids.append(mof_id)
                            values.append(value)
                except Exception:
                    continue
        
        elif isinstance(data, pd.DataFrame):
            # ğŸ”¥ æ™ºèƒ½å¤„ç†ä»»æ„åˆ—å
            # 1. é¦–å…ˆç›´æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¯¥åˆ—åï¼ˆç”¨æˆ·å¯èƒ½ç›´æ¥æä¾›å®Œæ•´åˆ—åï¼‰
            if property_name in data.columns:
                mask = data[property_name].notna()
                ids = data.loc[mask, 'qmof_id'].tolist() if 'qmof_id' in data.columns else data.index.tolist()
                values = data.loc[mask, property_name].tolist()
            # 2. å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•æ‹¼æ¥ theory_levelï¼ˆå‘åå…¼å®¹ï¼‰
            else:
                col_name = f'outputs.{theory_level}.{property_name}'
                if col_name in data.columns:
                    mask = data[col_name].notna()
                    ids = data.loc[mask, 'qmof_id'].tolist() if 'qmof_id' in data.columns else data.index.tolist()
                    values = data.loc[mask, col_name].tolist()
                else:
                    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆä¸æŠ¥é”™ï¼Œè®©è°ƒç”¨è€…å¤„ç†ï¼‰
                    pass
        
        return ids, values
    
    def extract_features_and_target(
        self,
        data: pd.DataFrame,
        target_column: str,
        feature_columns: List[str] = None,
        auto_select_numeric: bool = True
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """
        ğŸ”¥ æ–°æ–¹æ³•ï¼šä»DataFrameä¸­æå–ç‰¹å¾å’Œç›®æ ‡ï¼ˆæ”¯æŒä»»æ„åˆ—åï¼‰
        
        Args:
            data: è¾“å…¥DataFrame
            target_column: ç›®æ ‡åˆ—åï¼ˆç”¨æˆ·é€‰æ‹©çš„ä»»æ„åˆ—ï¼‰
            feature_columns: ç‰¹å¾åˆ—ååˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            auto_select_numeric: å¦‚æœfeature_columnsä¸ºNoneï¼Œæ˜¯å¦è‡ªåŠ¨é€‰æ‹©æ‰€æœ‰æ•°å€¼åˆ—ä½œä¸ºç‰¹å¾
            
        Returns:
            (ç‰¹å¾DataFrame, ç›®æ ‡Series)å…ƒç»„
        """
        if target_column not in data.columns:
            raise ValueError(f"ç›®æ ‡åˆ— '{target_column}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        # è·å–ç›®æ ‡
        y = data[target_column].copy()
        
        # ç¡®å®šç‰¹å¾åˆ—
        if feature_columns is None:
            if auto_select_numeric:
                # è‡ªåŠ¨é€‰æ‹©æ‰€æœ‰æ•°å€¼åˆ—ï¼Œæ’é™¤ç›®æ ‡åˆ—
                numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
                feature_columns = [col for col in numeric_cols if col != target_column]
            else:
                # ä½¿ç”¨é™¤ç›®æ ‡åˆ—å¤–çš„æ‰€æœ‰åˆ—
                feature_columns = [col for col in data.columns if col != target_column]
        
        # è·å–ç‰¹å¾
        X = data[feature_columns].copy()
        
        # åªä¿ç•™æ•°å€¼å‹ç‰¹å¾
        X = X.select_dtypes(include=[np.number])
        
        self.feature_names = list(X.columns)
        
        return X, y
    
    def normalize_features(
        self,
        X: Union[pd.DataFrame, np.ndarray],
        method: str = 'standard',
        fit: bool = True
    ) -> np.ndarray:
        """
        æ ‡å‡†åŒ–ç‰¹å¾
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            method: æ ‡å‡†åŒ–æ–¹æ³•ï¼ˆ'standard', 'minmax'ï¼‰
            fit: æ˜¯å¦æ‹Ÿåˆscaler
            
        Returns:
            æ ‡å‡†åŒ–åçš„ç‰¹å¾çŸ©é˜µ
        """
        if method == 'standard':
            if fit or self.scaler is None:
                self.scaler = StandardScaler()
                X_normalized = self.scaler.fit_transform(X)
            else:
                X_normalized = self.scaler.transform(X)
        
        elif method == 'minmax':
            if fit or self.scaler is None:
                self.scaler = MinMaxScaler()
                X_normalized = self.scaler.fit_transform(X)
            else:
                X_normalized = self.scaler.transform(X)
        
        else:
            X_normalized = X
        
        return X_normalized
    
    def split_data(
        self,
        X: Union[pd.DataFrame, np.ndarray],
        y: Union[pd.Series, np.ndarray],
        train_ratio: float = 0.8,
        val_ratio: float = 0.1,
        test_ratio: float = 0.1,
        random_state: int = 42
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å‘é‡
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
            
        Returns:
            (X_train, X_val, X_test, y_train, y_val, y_test)å…ƒç»„
        """
        # é¦–å…ˆåˆ†å‡ºæµ‹è¯•é›†
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y,
            test_size=test_ratio,
            random_state=random_state
        )
        
        # ä»å‰©ä½™æ•°æ®ä¸­åˆ†å‡ºéªŒè¯é›†
        val_ratio_adjusted = val_ratio / (train_ratio + val_ratio)
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp,
            test_size=val_ratio_adjusted,
            random_state=random_state
        )
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def remove_outliers(
        self,
        X: pd.DataFrame,
        y: pd.Series = None,
        std_threshold: float = 3.0
    ) -> Tuple[pd.DataFrame, Optional[pd.Series]]:
        """
        ç§»é™¤å¼‚å¸¸å€¼
        
        Args:
            X: ç‰¹å¾DataFrame
            y: ç›®æ ‡Series
            std_threshold: æ ‡å‡†å·®é˜ˆå€¼
            
        Returns:
            (è¿‡æ»¤åçš„X, è¿‡æ»¤åçš„y)å…ƒç»„
        """
        # è®¡ç®—Z-score
        z_scores = np.abs((X - X.mean()) / X.std())
        
        # æ‰¾å‡ºæ‰€æœ‰ç‰¹å¾éƒ½åœ¨é˜ˆå€¼å†…çš„æ ·æœ¬
        mask = (z_scores < std_threshold).all(axis=1)
        
        X_filtered = X[mask]
        y_filtered = y[mask] if y is not None else None
        
        return X_filtered, y_filtered
    
    def handle_missing_values(
        self,
        X: pd.DataFrame,
        strategy: str = 'mean'
    ) -> pd.DataFrame:
        """
        å¤„ç†ç¼ºå¤±å€¼
        
        Args:
            X: ç‰¹å¾DataFrame
            strategy: å¡«å……ç­–ç•¥ï¼ˆ'mean', 'median', 'drop'ï¼‰
            
        Returns:
            å¤„ç†åçš„DataFrame
        """
        if strategy == 'drop':
            return X.dropna()
        
        elif strategy == 'mean':
            return X.fillna(X.mean())
        
        elif strategy == 'median':
            return X.fillna(X.median())
        
        else:
            return X
    
    def get_statistics(self, data: Union[pd.DataFrame, np.ndarray]) -> Dict[str, Any]:
        """
        è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            data: æ•°æ®
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if isinstance(data, pd.DataFrame):
            stats = {
                'count': len(data),
                'shape': data.shape,
                'columns': list(data.columns),
                'dtypes': data.dtypes.to_dict(),
                'missing': data.isnull().sum().to_dict(),
                'numeric_summary': data.describe().to_dict(),
            }
        
        elif isinstance(data, np.ndarray):
            stats = {
                'count': data.shape[0],
                'shape': data.shape,
                'mean': np.mean(data, axis=0).tolist() if data.ndim > 1 else float(np.mean(data)),
                'std': np.std(data, axis=0).tolist() if data.ndim > 1 else float(np.std(data)),
                'min': np.min(data, axis=0).tolist() if data.ndim > 1 else float(np.min(data)),
                'max': np.max(data, axis=0).tolist() if data.ndim > 1 else float(np.max(data)),
            }
        
        else:
            stats = {'error': 'ä¸æ”¯æŒçš„æ•°æ®ç±»å‹'}
        
        return stats
    
    def prepare_for_cgcnn(
        self,
        structures: Dict[str, Any],
        properties: Dict[str, float]
    ) -> List[Dict[str, Any]]:
        """
        ä¸ºCGCNNå‡†å¤‡æ•°æ®
        
        Args:
            structures: {mof_id: Structure}å­—å…¸
            properties: {mof_id: property_value}å­—å…¸
            
        Returns:
            CGCNNæ ¼å¼çš„æ•°æ®åˆ—è¡¨
        """
        data = []
        
        for mof_id, structure in structures.items():
            if mof_id in properties:
                data.append({
                    'id': mof_id,
                    'structure': structure,
                    'target': properties[mof_id],
                })
        
        return data
    
    def prepare_for_moformer(
        self,
        mofid_data: Union[List[Dict], pd.DataFrame],
        target_property: str
    ) -> Tuple[List[str], List[float]]:
        """
        ä¸ºMOFormerå‡†å¤‡æ•°æ®
        
        Args:
            mofid_data: MOFidæ•°æ®
            target_property: ç›®æ ‡å±æ€§
            
        Returns:
            (MOFidåˆ—è¡¨, ç›®æ ‡å€¼åˆ—è¡¨)å…ƒç»„
        """
        mofids = []
        targets = []
        
        if isinstance(mofid_data, list):
            for entry in mofid_data:
                # æå–MOFid
                mofid = None
                if 'info' in entry and 'mofid' in entry.get('info', {}):
                    mofid = entry['info']['mofid'].get('mofid')
                elif 'mofid' in entry:
                    mofid = entry['mofid']
                
                # æå–ç›®æ ‡å€¼
                target = None
                if 'outputs' in entry:
                    for theory in ['pbe', 'hle17', 'hse06']:
                        if theory in entry['outputs']:
                            target = entry['outputs'][theory].get(target_property)
                            if target is not None:
                                break
                
                if mofid and target is not None:
                    mofids.append(mofid)
                    targets.append(target)
        
        elif isinstance(mofid_data, pd.DataFrame):
            mofid_col = 'info.mofid.mofid' if 'info.mofid.mofid' in mofid_data.columns else 'mofid'
            target_col = f'outputs.pbe.{target_property}' if f'outputs.pbe.{target_property}' in mofid_data.columns else target_property
            
            if mofid_col in mofid_data.columns and target_col in mofid_data.columns:
                mask = mofid_data[target_col].notna() & mofid_data[mofid_col].notna()
                mofids = mofid_data.loc[mask, mofid_col].tolist()
                targets = mofid_data.loc[mask, target_col].tolist()
        
        return mofids, targets


