"""
MOFé¢„æµ‹å¹³å° - Streamlitä¸»åº”ç”¨
MOF Prediction Platform - Main Streamlit Application
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import sys
import json

# æ·»åŠ è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from config import *
from utils import DataLoader, DataProcessor, ModelRouter, FileHandler, setup_logger
from models import (
    CGCNNModel, MOFormerModel, EnsembleModel,
    TraditionalMLModel, MLEnsembleModel, CrossValidator, HyperparameterOptimizer,
    get_available_models, get_model_display_names, create_auto_ensemble, quick_optimize
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="MOFé¢„æµ‹å¹³å°",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded",
)

# åˆå§‹åŒ–session state
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'model' not in st.session_state:
    st.session_state.model = None
if 'predictions' not in st.session_state:
    st.session_state.predictions = None
if 'available_columns' not in st.session_state:
    st.session_state.available_columns = []
if 'numeric_columns' not in st.session_state:
    st.session_state.numeric_columns = []
if 'selected_target' not in st.session_state:
    st.session_state.selected_target = None

# ä¾§è¾¹æ 
with st.sidebar:
    # æ˜¾ç¤º logoï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    logo_path = ASSETS_DIR / "logo.png"
    if logo_path.exists():
        st.image(str(logo_path))
    
    st.title("ğŸ§ª MOFé¢„æµ‹å¹³å°")
    st.markdown("---")
    
    page = st.radio(
        "å¯¼èˆª",
        ["ğŸ  ä¸»é¡µ", "ğŸ“‚ æ•°æ®ç®¡ç†", "ğŸ¤– æ¨¡å‹è®­ç»ƒ", "ğŸ”® æ€§è´¨é¢„æµ‹", "ğŸ“Š ç»“æœåˆ†æ", "âš™ï¸ è®¾ç½®"],
        key="navigation"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“ˆ ç³»ç»ŸçŠ¶æ€")
    st.info(f"æ•°æ®å·²åŠ è½½: {'âœ…' if st.session_state.data_loaded else 'âŒ'}")
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è®­ç»ƒï¼ˆå…¼å®¹ä¸åŒæ¨¡å‹ç±»å‹ï¼‰
    model_trained = False
    if st.session_state.model:
        model_trained = getattr(st.session_state.model, 'is_trained', False) or getattr(st.session_state.model, 'model', None) is not None
    st.info(f"æ¨¡å‹å·²è®­ç»ƒ: {'âœ…' if model_trained else 'âŒ'}")

# ä¸»é¡µ
if page == "ğŸ  ä¸»é¡µ":
    st.title("ğŸ§ª MOFé¢„æµ‹å¹³å°")
    st.markdown("### åŸºäºCGCNNå’ŒMOFormerçš„æ™ºèƒ½é‡‘å±æœ‰æœºæ¡†æ¶ææ–™æ€§è´¨é¢„æµ‹ç³»ç»Ÿ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ¤– å¤šæ¨¡å‹æ¶æ„")
        st.write("""
        - **CGCNN**: åŸºäº3Dæ™¶ä½“ç»“æ„
        - **MOFormer**: åŸºäºMOFidæ–‡æœ¬
        - **ä¼ ç»ŸML**: XGBoost, LightGBM, CatBoostç­‰
        - **é›†æˆæ¨¡å‹**: å¤šç§é›†æˆç­–ç•¥
        """)
    
    with col2:
        st.markdown("#### ğŸ“Š æ”¯æŒçš„æ€§è´¨")
        st.write("""
        - èƒ½å¸¦éš™ (Band Gap)
        - å¯¼å¸¦/ä»·å¸¦ä½ç½®
        - å­”å¾„ç‰¹å¾
        - å¯†åº¦å’Œèƒ½é‡
        """)
    
    with col3:
        st.markdown("#### ğŸ” æ ¸å¿ƒåŠŸèƒ½")
        st.write("""
        - KæŠ˜äº¤å‰éªŒè¯
        - è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ–
        - SHAPå¯è§£é‡Šæ€§åˆ†æ
        - æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        """)
    
    st.markdown("---")
    st.markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹")
    st.info("""
    1. ğŸ“‚ **æ•°æ®ç®¡ç†**: ä¸Šä¼ æ•°æ®æˆ–åŠ è½½QMOFæ•°æ®é›†
    2. ğŸ¤– **æ¨¡å‹è®­ç»ƒ**: é€‰æ‹©æ¨¡å‹å¹¶è®­ç»ƒ
    3. ğŸ”® **æ€§è´¨é¢„æµ‹**: å¯¹æ–°MOFè¿›è¡Œé¢„æµ‹
    4. ğŸ“Š **ç»“æœåˆ†æ**: å¯è§†åŒ–å’Œè§£é‡Šé¢„æµ‹ç»“æœ
    """)
    
    st.markdown("### ğŸ“š å‚è€ƒæ–‡çŒ®")
    st.markdown("""
    - **CGCNN**: Xie & Grossman, *Phys. Rev. Lett.* 2018
    - **MOFormer**: Cao et al., *JACS* 2023  
    - **QMOF**: Rosen et al., *npj Comput. Mater.* 2022
    """)

# æ•°æ®ç®¡ç†é¡µé¢
elif page == "ğŸ“‚ æ•°æ®ç®¡ç†":
    st.title("ğŸ“‚ æ•°æ®ç®¡ç†")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ•°æ®", "ğŸ“¦ QMOFæ•°æ®é›†", "ğŸ“Š æ•°æ®é¢„è§ˆ"])
    
    with tab1:
        st.markdown("### ä¸Šä¼ æœ¬åœ°æ•°æ®")
        
        upload_type = st.selectbox(
            "é€‰æ‹©æ•°æ®ç±»å‹",
            ["CIFæ–‡ä»¶ï¼ˆæ™¶ä½“ç»“æ„ï¼‰", "JSONæ–‡ä»¶ï¼ˆQMOFæ ¼å¼ï¼‰", "CSVæ–‡ä»¶ï¼ˆè¡¨æ ¼æ•°æ®ï¼‰"]
        )
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=['cif', 'json', 'csv', 'zip'],
            accept_multiple_files=False
        )
        
        if uploaded_file:
            st.success(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ : {uploaded_file.name}")
            
            # ä¿å­˜æ–‡ä»¶
            save_path = RAW_DATA_DIR / uploaded_file.name
            with open(save_path, 'wb') as f:
                f.write(uploaded_file.getbuffer())
            
            if st.button("ğŸ”„ åŠ è½½æ•°æ®"):
                try:
                    data_loader = DataLoader(QMOF_CONFIG)
                    data, data_type = data_loader.load_from_file(save_path)
                    
                    st.session_state.data = data
                    st.session_state.data_type = data_type
                    st.session_state.data_loaded = True
                    
                    # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæå–åˆ—å
                    if isinstance(data, pd.DataFrame):
                        st.session_state.available_columns = list(data.columns)
                        st.session_state.numeric_columns = list(data.select_dtypes(include=[np.number]).columns)
                    elif isinstance(data, list) and len(data) > 0:
                        # ğŸ”¥ å°†åˆ—è¡¨è½¬æ¢ä¸ºDataFrame
                        try:
                            df_temp = pd.json_normalize(data)
                            st.session_state.data = df_temp  # æ›¿æ¢ä¸ºDataFrame
                            data = df_temp
                            st.session_state.available_columns = list(df_temp.columns)
                            st.session_state.numeric_columns = list(df_temp.select_dtypes(include=[np.number]).columns)
                        except Exception as e:
                            st.warning(f"âš ï¸ æ— æ³•è½¬æ¢ä¸ºDataFrame: {e}")
                            st.session_state.available_columns = []
                            st.session_state.numeric_columns = []
                    elif isinstance(data, dict):
                        st.session_state.available_columns = []
                        st.session_state.numeric_columns = []
                    
                    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼ç±»å‹: {data_type}")
                    st.info(f"ğŸ” æ£€æµ‹åˆ° {len(st.session_state.numeric_columns)} ä¸ªæ•°å€¼å‹åˆ—å¯ç”¨äºé¢„æµ‹")
                    
                    # æ˜¾ç¤ºæ‘˜è¦
                    summary = data_loader.get_data_summary(data, data_type)
                    st.json(summary)
                    
                except Exception as e:
                    st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
    
    with tab2:
        st.markdown("### QMOFæ•°æ®é›†")
        
        st.info("ğŸ’¡ **è®­ç»ƒæ¨è**ï¼šé€‰æ‹© **'qmof.csvï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰'** ä»¥è·å¾—æœ€ä½³å…¼å®¹æ€§")
        
        qmof_source = st.selectbox(
            "é€‰æ‹©QMOFæ•°æ®æº",
            ["qmof.csvï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰", "qmof.jsonï¼ˆå±æ€§æ•°æ®ï¼‰", 
             "ç»“æ„æ•°æ®ï¼ˆCIFï¼‰", "å®Œæ•´ç»“æ„æ•°æ®ï¼ˆJSONï¼‰"]
        )
        
        limit = st.number_input("é™åˆ¶åŠ è½½æ•°é‡ï¼ˆ0=å…¨éƒ¨ï¼‰", min_value=0, max_value=20373, value=100)
        
        if st.button("ğŸ“¥ åŠ è½½QMOFæ•°æ®"):
            try:
                data_loader = DataLoader(QMOF_CONFIG)
                
                source_map = {
                    "qmof.jsonï¼ˆå±æ€§æ•°æ®ï¼‰": "json",
                    "qmof.csvï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰": "csv",
                    "ç»“æ„æ•°æ®ï¼ˆCIFï¼‰": "cif",
                    "å®Œæ•´ç»“æ„æ•°æ®ï¼ˆJSONï¼‰": "structures",
                }
                
                with st.spinner("â³ åŠ è½½QMOFæ•°æ®ä¸­..."):
                    data, data_type = data_loader.load_qmof_data(
                        source_map[qmof_source],
                        limit=limit if limit > 0 else None
                    )
                
                st.session_state.data = data
                st.session_state.data_type = data_type
                st.session_state.data_loaded = True
                
                # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šè‡ªåŠ¨æå–æ‰€æœ‰å¯ç”¨çš„åˆ—å
                if isinstance(data, pd.DataFrame):
                    # è·å–æ‰€æœ‰åˆ—å
                    st.session_state.available_columns = list(data.columns)
                    # è·å–æ‰€æœ‰æ•°å€¼å‹åˆ—åï¼ˆå¯ä»¥ä½œä¸ºç›®æ ‡å±æ€§ï¼‰
                    st.session_state.numeric_columns = list(data.select_dtypes(include=[np.number]).columns)
                elif isinstance(data, list) and len(data) > 0:
                    # ğŸ”¥ å…³é”®ï¼šå°†åˆ—è¡¨è½¬æ¢ä¸ºDataFrameï¼Œè¿™æ ·åç»­å¤„ç†æ›´æ–¹ä¾¿
                    try:
                        df_temp = pd.json_normalize(data)
                        st.session_state.data = df_temp  # æ›¿æ¢ä¸ºDataFrame
                        data = df_temp  # æ›´æ–°æœ¬åœ°å˜é‡
                        st.session_state.available_columns = list(df_temp.columns)
                        st.session_state.numeric_columns = list(df_temp.select_dtypes(include=[np.number]).columns)
                    except Exception as e:
                        st.warning(f"âš ï¸ æ— æ³•è½¬æ¢ä¸ºDataFrame: {e}")
                        st.session_state.available_columns = []
                        st.session_state.numeric_columns = []
                elif isinstance(data, dict):
                    st.session_state.available_columns = []
                    st.session_state.numeric_columns = []
                
                st.success(f"âœ… QMOFæ•°æ®åŠ è½½æˆåŠŸï¼")
                st.info(f"æ•°æ®ç±»å‹: {data_type}")
                st.info(f"ğŸ” æ£€æµ‹åˆ° {len(st.session_state.numeric_columns)} ä¸ªæ•°å€¼å‹åˆ—å¯ç”¨äºé¢„æµ‹")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                if isinstance(data, pd.DataFrame):
                    st.write(f"ğŸ“Š åŠ è½½äº† {len(data)} ä¸ªMOFï¼Œ{len(data.columns)} ä¸ªç‰¹å¾")
                    st.dataframe(data.head())
                elif isinstance(data, dict):
                    st.write(f"ğŸ“Š åŠ è½½äº† {len(data)} ä¸ªç»“æ„")
                elif isinstance(data, list):
                    st.write(f"ğŸ“Š åŠ è½½äº† {len(data)} æ¡è®°å½•")
                
            except Exception as e:
                st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
                st.exception(e)
    
    with tab3:
        st.markdown("### æ•°æ®é¢„è§ˆ")
        
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆåŠ è½½æ•°æ®")
        else:
            data = st.session_state.data
            data_type = st.session_state.data_type
            
            st.success(f"å½“å‰æ•°æ®ç±»å‹: **{data_type}**")
            
            if isinstance(data, pd.DataFrame):
                st.dataframe(data, use_container_width=True)
                
                st.markdown("#### ç»Ÿè®¡ä¿¡æ¯")
                st.write(data.describe())
                
            elif isinstance(data, list):
                st.write(f"è®°å½•æ•°: {len(data)}")
                st.json(data[:3])  # æ˜¾ç¤ºå‰3æ¡
                
            elif isinstance(data, dict):
                st.write(f"ç»“æ„æ•°: {len(data)}")
                st.write("MOF IDs:", list(data.keys())[:10])

# æ¨¡å‹è®­ç»ƒé¡µé¢
elif page == "ğŸ¤– æ¨¡å‹è®­ç»ƒ":
    st.title("ğŸ¤– æ¨¡å‹è®­ç»ƒ")
    
    if not st.session_state.data_loaded:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€æ•°æ®ç®¡ç†ã€‘é¡µé¢åŠ è½½æ•°æ®")
    else:
        # æ¨¡å‹è·¯ç”±æ¨è
        st.markdown("### ğŸ§­ æ™ºèƒ½æ¨¡å‹æ¨è")
        
        router = ModelRouter()
        recommendation = router.recommend_model(
            data=st.session_state.data
        )
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.info(f"""
            **æ¨èæ¨¡å‹**: {recommendation['primary'].upper()}
            
            **ç†ç”±**: {recommendation['reason']}
            
            **ç½®ä¿¡åº¦**: {recommendation['confidence']*100:.0f}%
            """)
        
        with col2:
            st.write("**å¤‡é€‰æ¨¡å‹**:")
            for alt in recommendation['alternatives']:
                st.write(f"- {alt.upper()}")
        
        # æ¨¡å‹é€‰æ‹©
        st.markdown("### ğŸ¯ é€‰æ‹©æ¨¡å‹")
        
        # æ·»åŠ æ¨¡å‹ç±»åˆ«é€‰æ‹©
        model_category = st.radio(
            "æ¨¡å‹ç±»åˆ«",
            ["ğŸ§  æ·±åº¦å­¦ä¹ æ¨¡å‹", "ğŸŒ² ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹", "ğŸ¯ é›†æˆæ¨¡å‹"],
            horizontal=True
        )
        
        if model_category == "ğŸ§  æ·±åº¦å­¦ä¹ æ¨¡å‹":
            model_choice = st.selectbox(
                "æ¨¡å‹ç±»å‹",
                ["CGCNN", "MOFormer"],
                index=["cgcnn", "moformer"].index(recommendation['primary']) if recommendation['primary'] in ["cgcnn", "moformer"] else 0
            )
        elif model_category == "ğŸŒ² ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹":
            # è·å–å¯ç”¨çš„ä¼ ç»ŸMLæ¨¡å‹
            available_models = get_available_models()
            display_names = get_model_display_names()
            
            # åªæ˜¾ç¤ºå¯ç”¨çš„æ¨¡å‹
            available_ml_models = {k: v for k, v in display_names.items() if available_models.get(k, False)}
            
            if not available_ml_models:
                st.error("âŒ æœªå®‰è£…ä¼ ç»Ÿæœºå™¨å­¦ä¹ åº“ã€‚è¯·è¿è¡Œ: pip install xgboost lightgbm catboost optuna")
                st.stop()
            
            model_choice = st.selectbox(
                "é€‰æ‹©ä¼ ç»ŸMLæ¨¡å‹",
                list(available_ml_models.keys()),
                format_func=lambda x: available_ml_models[x]
            )
        else:  # é›†æˆæ¨¡å‹
            ensemble_type = st.selectbox(
                "é›†æˆç±»å‹",
                ["æ·±åº¦å­¦ä¹ é›†æˆ", "ä¼ ç»ŸMLé›†æˆ (Voting)", "ä¼ ç»ŸMLé›†æˆ (Stacking)", "ä¼ ç»ŸMLé›†æˆ (Blending)"]
            )
            if ensemble_type == "æ·±åº¦å­¦ä¹ é›†æˆ":
                model_choice = "é›†æˆæ¨¡å‹"
            else:
                model_choice = ensemble_type
        
        # æ¨¡å‹é…ç½®
        st.markdown("### âš™ï¸ æ¨¡å‹é…ç½®")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            epochs = st.number_input("è®­ç»ƒè½®æ•°", min_value=10, max_value=500, value=100)
            batch_size = st.number_input("æ‰¹æ¬¡å¤§å°", min_value=8, max_value=128, value=32)
        
        with col2:
            learning_rate = st.select_slider(
                "å­¦ä¹ ç‡",
                options=[1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2],
                value=1e-3
            )
            train_ratio = st.slider("è®­ç»ƒé›†æ¯”ä¾‹", 0.5, 0.9, 0.8)
        
        with col3:
            val_ratio = st.slider("éªŒè¯é›†æ¯”ä¾‹", 0.05, 0.3, 0.1)
            test_ratio = 1.0 - train_ratio - val_ratio
            st.metric("æµ‹è¯•é›†æ¯”ä¾‹", f"{test_ratio:.2f}")
        
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šç›®æ ‡å±æ€§åŠ¨æ€é€‰æ‹©
        st.markdown("### ğŸ¯ ç›®æ ‡å±æ€§é€‰æ‹©")
        
        if len(st.session_state.numeric_columns) == 0:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°æ•°å€¼å‹åˆ—ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")
            st.stop()
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col_a, col_b = st.columns([3, 1])
        
        with col_a:
            # ğŸ”¥ ä½¿ç”¨å®é™…æ•°æ®ä¸­çš„åˆ—åï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç çš„å±æ€§
            property_choice = st.selectbox(
                "é€‰æ‹©è¦é¢„æµ‹çš„ç›®æ ‡åˆ—ï¼ˆä»æ‚¨çš„æ•°æ®ä¸­ï¼‰",
                st.session_state.numeric_columns,
                help="è¿™äº›æ˜¯æ‚¨æ•°æ®ä¸­çš„æ‰€æœ‰æ•°å€¼å‹åˆ—ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä»»æ„ä¸€ä¸ªä½œä¸ºé¢„æµ‹ç›®æ ‡"
            )
            
            # ä¿å­˜ç”¨æˆ·é€‰æ‹©
            st.session_state.selected_target = property_choice
        
        with col_b:
            # æ˜¾ç¤ºè¯¥åˆ—çš„ç»Ÿè®¡ä¿¡æ¯
            if isinstance(st.session_state.data, pd.DataFrame):
                # ğŸ”¥ å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿åˆ—å­˜åœ¨
                if property_choice in st.session_state.data.columns:
                    col_data = st.session_state.data[property_choice]
                    st.metric("æ•°æ®ç‚¹æ•°", len(col_data.dropna()))
                    st.metric("å¹³å‡å€¼", f"{col_data.mean():.3f}")
                    st.metric("æ ‡å‡†å·®", f"{col_data.std():.3f}")
                else:
                    st.warning(f"âš ï¸ åˆ— '{property_choice}' ä¸åœ¨å½“å‰æ•°æ®ä¸­")
        
        # æ˜¾ç¤ºè¯¥åˆ—çš„åˆ†å¸ƒ
        if isinstance(st.session_state.data, pd.DataFrame):
            # ğŸ”¥ å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿åˆ—å­˜åœ¨
            if property_choice in st.session_state.data.columns:
                import plotly.express as px
                col_data = st.session_state.data[property_choice].dropna()
                if len(col_data) > 0:
                    fig = px.histogram(col_data, nbins=50, title=f"{property_choice} åˆ†å¸ƒ")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("è¯¥åˆ—æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        
        st.success(f"âœ… å·²é€‰æ‹©ç›®æ ‡åˆ—: **{property_choice}**")
        
        # å¼€å§‹è®­ç»ƒ
        if st.button("ğŸš€ å¼€å§‹è®­ç»ƒ", type="primary"):
            try:
                data = st.session_state.data
                data_type = st.session_state.data_type
                
                # å‡†å¤‡è®­ç»ƒæ•°æ®
                with st.spinner("â³ å‡†å¤‡è®­ç»ƒæ•°æ®..."):
                    data_processor = DataProcessor()
                    
                    # è½¬æ¢æ•°æ®ä¸º DataFrameï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if not isinstance(data, pd.DataFrame):
                        st.info("ğŸ“Š æ£€æµ‹åˆ°éè¡¨æ ¼æ•°æ®ï¼Œæ­£åœ¨è½¬æ¢ä¸º DataFrame...")
                        
                        if isinstance(data, dict):
                            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œå°è¯•è½¬æ¢
                            if all(isinstance(v, dict) for v in data.values()):
                                # {id: {prop1: val1, prop2: val2, ...}} æ ¼å¼
                                data = pd.DataFrame.from_dict(data, orient='index')
                                data.index.name = 'qmof_id'
                                data.reset_index(inplace=True)
                                st.success(f"âœ… å·²è½¬æ¢ä¸º DataFrameï¼Œå…± {len(data)} è¡Œ")
                            else:
                                # å°è¯•ç›´æ¥è½¬æ¢
                                data = pd.DataFrame([data])
                        
                        elif isinstance(data, list):
                            # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼
                            if data and isinstance(data[0], dict):
                                data = pd.DataFrame(data)
                                st.success(f"âœ… å·²è½¬æ¢ä¸º DataFrameï¼Œå…± {len(data)} è¡Œ")
                            else:
                                st.error("âŒ æ— æ³•å°†åˆ—è¡¨æ•°æ®è½¬æ¢ä¸º DataFrame")
                                st.stop()
                        
                        else:
                            st.error(f"âŒ ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(data).__name__}")
                            st.warning("ğŸ’¡ å»ºè®®ï¼šè¯·åœ¨ã€æ•°æ®ç®¡ç†ã€‘é¡µé¢é€‰æ‹© **'qmof.csvï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰'** æ•°æ®æº")
                            st.stop()
                        
                        # æ›´æ–° session state
                        st.session_state.data = data
                    
                    # æ ¹æ®æ•°æ®ç±»å‹å’Œæ¨¡å‹ç±»å‹å‡†å¤‡æ•°æ®
                    if (model_category == "ğŸŒ² ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹") or (model_category == "ğŸ¯ é›†æˆæ¨¡å‹" and "MLé›†æˆ" in str(model_choice)):
                        # ä¼ ç»ŸMLæ¨¡å‹ä½¿ç”¨è¡¨æ ¼æ•°æ®
                        if not isinstance(data, pd.DataFrame):
                            st.error("âŒ ä¼ ç»ŸMLæ¨¡å‹éœ€è¦è¡¨æ ¼æ•°æ®æ ¼å¼")
                            st.stop()
                        
                        if property_choice not in data.columns:
                            st.error(f"âŒ æ•°æ®ä¸­æœªæ‰¾åˆ°ç›®æ ‡å±æ€§ '{property_choice}'")
                            st.stop()
                        
                        # è‡ªåŠ¨é€‰æ‹©æ•°å€¼å‹ç‰¹å¾åˆ—
                        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
                        feature_cols = [col for col in numeric_cols if col != property_choice]
                        
                        if len(feature_cols) == 0:
                            st.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°å€¼ç‰¹å¾åˆ—")
                            st.stop()
                        
                        st.info(f"ğŸ“Š ä½¿ç”¨ {len(feature_cols)} ä¸ªç‰¹å¾åˆ—è¿›è¡Œè®­ç»ƒ")
                        
                        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
                        required_cols = feature_cols + [property_choice]
                        valid_data = data[required_cols].dropna()
                        st.info(f"ğŸ“Š æœ‰æ•ˆæ•°æ®: {len(valid_data)} / {len(data)} æ¡")
                        
                        if len(valid_data) < 10:
                            st.error("âŒ æœ‰æ•ˆæ•°æ®å¤ªå°‘ï¼ˆ<10æ¡ï¼‰ï¼Œæ— æ³•è®­ç»ƒ")
                            st.stop()
                        
                        # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
                        X = valid_data[feature_cols].values
                        y = valid_data[property_choice].values
                        
                        # æ•°æ®åˆ’åˆ†
                        from sklearn.model_selection import train_test_split
                        
                        X_train, X_temp, y_train, y_temp = train_test_split(
                            X, y, test_size=(1-train_ratio), random_state=42
                        )
                        X_val, X_test, y_val, y_test = train_test_split(
                            X_temp, y_temp, test_size=(test_ratio/(test_ratio+val_ratio)), random_state=42
                        )
                        
                        st.success(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(X_train)}, éªŒè¯é›† {len(X_val)}, æµ‹è¯•é›† {len(X_test)}")
                        
                        # å­˜å‚¨æµ‹è¯•é›†
                        st.session_state.test_data = {'X': X_test, 'y': y_test, 'feature_names': feature_cols}
                    
                    elif model_choice in ["CGCNN", "é›†æˆæ¨¡å‹"]:
                        # CGCNN éœ€è¦è¡¨æ ¼æ•°æ®
                        if not isinstance(data, pd.DataFrame):
                            st.error("âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°åŠ è½½æ•°æ®")
                            st.stop()
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡å±æ€§
                        if property_choice not in data.columns:
                            st.error(f"âŒ æ•°æ®ä¸­æœªæ‰¾åˆ°ç›®æ ‡å±æ€§ '{property_choice}'")
                            st.stop()
                        
                        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
                        valid_data = data.dropna(subset=[property_choice])
                        st.info(f"ğŸ“Š æœ‰æ•ˆæ•°æ®: {len(valid_data)} / {len(data)} æ¡")
                        
                        if len(valid_data) < 10:
                            st.error("âŒ æœ‰æ•ˆæ•°æ®å¤ªå°‘ï¼ˆ<10æ¡ï¼‰ï¼Œæ— æ³•è®­ç»ƒ")
                            st.stop()
                        
                        # æ•°æ®åˆ’åˆ†
                        from sklearn.model_selection import train_test_split
                        
                        train_df, temp_df = train_test_split(
                            valid_data, test_size=(1-train_ratio), random_state=42
                        )
                        val_df, test_df = train_test_split(
                            temp_df, test_size=(test_ratio/(test_ratio+val_ratio)), random_state=42
                        )
                        
                        st.success(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(train_df)}, éªŒè¯é›† {len(val_df)}, æµ‹è¯•é›† {len(test_df)}")
                        
                        # å­˜å‚¨æµ‹è¯•é›†
                        st.session_state.test_data = test_df
                    
                    elif model_choice == "MOFormer":
                        # MOFormer éœ€è¦æ–‡æœ¬æ•°æ®
                        if not isinstance(data, pd.DataFrame):
                            st.error("âŒ MOFormer æ¨¡å‹éœ€è¦ DataFrame æ ¼å¼çš„æ•°æ®")
                            st.stop()
                        
                        # æ£€æŸ¥ç›®æ ‡å±æ€§å’Œæ–‡æœ¬å­—æ®µ
                        if property_choice not in data.columns:
                            st.error(f"âŒ æ•°æ®ä¸­æœªæ‰¾åˆ°ç›®æ ‡å±æ€§ '{property_choice}'")
                            st.stop()
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ mofid æˆ– smiles
                        text_field = None
                        use_index_as_text = False
                        if 'mofid' in data.columns:
                            text_field = 'mofid'
                        elif 'smiles' in data.columns:
                            text_field = 'smiles'
                        else:
                            st.warning("âš ï¸ æ•°æ®ä¸­æœªæ‰¾åˆ° 'mofid' æˆ– 'smiles' å­—æ®µï¼Œå°†ä½¿ç”¨ç´¢å¼•ä½œä¸º ID")
                            use_index_as_text = True
                            text_field = None  # ä¸ä½¿ç”¨åˆ—åï¼Œè€Œæ˜¯æ ‡è®°ä½¿ç”¨ç´¢å¼•
                        
                        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
                        valid_data = data.dropna(subset=[property_choice])
                        st.info(f"ğŸ“Š æœ‰æ•ˆæ•°æ®: {len(valid_data)} / {len(data)} æ¡")
                        
                        if len(valid_data) < 10:
                            st.error("âŒ æœ‰æ•ˆæ•°æ®å¤ªå°‘ï¼ˆ<10æ¡ï¼‰ï¼Œæ— æ³•è®­ç»ƒ")
                            st.stop()
                        
                        # æ•°æ®åˆ’åˆ†
                        from sklearn.model_selection import train_test_split
                        
                        train_df, temp_df = train_test_split(
                            valid_data, test_size=(1-train_ratio), random_state=42
                        )
                        val_df, test_df = train_test_split(
                            temp_df, test_size=(test_ratio/(test_ratio+val_ratio)), random_state=42
                        )
                        
                        st.success(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(train_df)}, éªŒè¯é›† {len(val_df)}, æµ‹è¯•é›† {len(test_df)}")
                        
                        # å­˜å‚¨æµ‹è¯•é›†
                        st.session_state.test_data = test_df
                
                # åˆ›å»ºæ¨¡å‹
                with st.spinner(f"ğŸ”¨ æ„å»º{model_choice}æ¨¡å‹..."):
                    if model_category == "ğŸŒ² ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹":
                        # åˆ›å»ºä¼ ç»ŸMLæ¨¡å‹
                        model = TraditionalMLModel(model_type=model_choice)
                        st.success(f"âœ… {get_model_display_names()[model_choice]} æ¨¡å‹åˆ›å»ºå®Œæˆï¼")
                        
                    elif "MLé›†æˆ" in str(model_choice):
                        # åˆ›å»ºä¼ ç»ŸMLé›†æˆæ¨¡å‹
                        if "Voting" in model_choice:
                            ensemble_method = 'voting'
                        elif "Stacking" in model_choice:
                            ensemble_method = 'stacking'
                        else:
                            ensemble_method = 'blending'
                        
                        # åˆ›å»ºå¤šä¸ªåŸºæ¨¡å‹
                        base_model_types = ['random_forest', 'gradient_boosting', 'xgboost', 'lightgbm']
                        available = get_available_models()
                        base_model_types = [mt for mt in base_model_types if available.get(mt, False)]
                        
                        if len(base_model_types) < 2:
                            st.error("âŒ å¯ç”¨çš„åŸºæ¨¡å‹å¤ªå°‘ï¼Œæ— æ³•åˆ›å»ºé›†æˆæ¨¡å‹")
                            st.stop()
                        
                        base_models = []
                        for mt in base_model_types:
                            m = TraditionalMLModel(model_type=mt)
                            base_models.append((mt, m.model))
                        
                        model = MLEnsembleModel(
                            base_models=base_models,
                            ensemble_method=ensemble_method
                        )
                        st.success(f"âœ… é›†æˆæ¨¡å‹åˆ›å»ºå®Œæˆï¼ä½¿ç”¨ {len(base_models)} ä¸ªåŸºæ¨¡å‹")
                    
                    elif model_choice == "CGCNN":
                        config = CGCNN_CONFIG.copy()
                        config.update({'batch_size': batch_size, 'lr': learning_rate})
                        model = CGCNNModel(config)
                        model.build_model()
                        st.success("âœ… æ¨¡å‹æ„å»ºå®Œæˆï¼")
                    elif model_choice == "MOFormer":
                        config = MOFORMER_CONFIG.copy()
                        config.update({'batch_size': batch_size, 'lr': learning_rate})
                        model = MOFormerModel(config)
                        model.build_model()
                        st.success("âœ… æ¨¡å‹æ„å»ºå®Œæˆï¼")
                    else:  # Deep Learning Ensemble
                        config = ENSEMBLE_CONFIG.copy()
                        model = EnsembleModel(config)
                        model.build_model()
                        st.success("âœ… æ¨¡å‹æ„å»ºå®Œæˆï¼")
                
                # å¼€å§‹è®­ç»ƒ
                st.markdown("### ğŸ“ˆ è®­ç»ƒè¿›åº¦")
                progress_bar = st.progress(0)
                status_text = st.empty()
                loss_chart = st.empty()
                
                # åˆ›å»ºä¸´æ—¶å®¹å™¨æ˜¾ç¤ºè®­ç»ƒæ—¥å¿—
                log_container = st.expander("æŸ¥çœ‹è¯¦ç»†è®­ç»ƒæ—¥å¿—", expanded=True)
                
                with log_container:
                    st.write("ğŸ”„ å¼€å§‹è®­ç»ƒ...")
                    
                    # ä¼ ç»ŸMLæ¨¡å‹è®­ç»ƒ
                    if (model_category == "ğŸŒ² ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹") or (model_category == "ğŸ¯ é›†æˆæ¨¡å‹" and "MLé›†æˆ" in str(model_choice)):
                        st.write(f"ğŸš€ å¼€å§‹è®­ç»ƒ {model_choice} æ¨¡å‹...")
                        import time
                        start_time = time.time()
                        
                        # è®­ç»ƒæ¨¡å‹
                        history = model.train(
                            X_train=X_train,
                            y_train=y_train,
                            X_val=X_val,
                            y_val=y_val,
                            feature_names=feature_cols
                        )
                        
                        training_time = time.time() - start_time
                        st.write(f"âœ… è®­ç»ƒå®Œæˆï¼ç”¨æ—¶: {training_time:.2f}ç§’")
                        
                        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
                        y_test_pred = model.predict(X_test)
                        
                        # ä¿å­˜é¢„æµ‹ç»“æœ
                        st.session_state.predictions = {
                            'y_true': y_test,
                            'y_pred': y_test_pred,
                            'dataset_name': 'æµ‹è¯•é›†',
                            'training_time': training_time
                        }
                        
                        # è®¡ç®—æŒ‡æ ‡
                        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
                        mae = mean_absolute_error(y_test, y_test_pred)
                        rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
                        r2 = r2_score(y_test, y_test_pred)
                        
                        # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
                        col_metric1, col_metric2, col_metric3, col_metric4 = st.columns(4)
                        with col_metric1:
                            st.metric("RÂ² Score", f"{r2:.4f}", help="å†³å®šç³»æ•°ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½")
                        with col_metric2:
                            st.metric("MAE", f"{mae:.4f}", help="å¹³å‡ç»å¯¹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½")
                        with col_metric3:
                            st.metric("RMSE", f"{rmse:.4f}", help="å‡æ–¹æ ¹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½")
                        with col_metric4:
                            mape = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100 if np.all(y_test != 0) else 0
                            st.metric("MAPE", f"{mape:.2f}%", help="å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®")
                        
                        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
                        feature_importance = model.get_feature_importance()
                        if feature_importance is not None:
                            st.session_state.feature_importance = {
                                'importance': feature_importance,
                                'feature_names': feature_cols
                            }
                        
                        # åˆ›å»ºç®€å•çš„è®­ç»ƒå†å²ï¼ˆé€‚é…ç°æœ‰å¯è§†åŒ–ï¼‰
                        train_score = model.history['train_scores'][0] if model.history['train_scores'] else r2
                        val_score = model.history['val_scores'][0] if model.history['val_scores'] else r2
                        
                        history = {
                            'train_loss': [1 - train_score],
                            'val_loss': [1 - val_score],
                            'train_r2': [train_score],
                            'val_r2': [val_score]
                        }
                        st.session_state.training_history = history
                        
                        progress_bar.progress(100)
                        
                        # ğŸ”¥ è®­ç»ƒå®Œæˆåç«‹å³å±•ç¤ºå®Œæ•´ç»“æœåˆ†æ
                        st.markdown("---")
                        st.markdown("## ğŸ“Š è®­ç»ƒç»“æœåˆ†æ")
                        
                        # å¯¼å…¥å¯è§†åŒ–å‡½æ•°
                        from src.visualization import (
                            plot_predictions_scatter,
                            plot_residuals,
                            plot_error_distribution,
                            plot_feature_importance_bar,
                            create_shap_analysis
                        )
                        
                        # 1. é¢„æµ‹ç»“æœå¯¹æ¯”
                        st.markdown("### ğŸ¯ é¢„æµ‹ç»“æœå¯¹æ¯”")
                        col_pred1, col_pred2 = st.columns(2)
                        
                        with col_pred1:
                            st.plotly_chart(
                                plot_predictions_scatter(y_test, y_test_pred, 'æµ‹è¯•é›†'),
                                use_container_width=True
                            )
                        
                        with col_pred2:
                            st.plotly_chart(
                                plot_residuals(y_test, y_test_pred),
                                use_container_width=True
                            )
                        
                        # 2. è¯¯å·®åˆ†æ
                        st.markdown("### ğŸ“‰ è¯¯å·®åˆ†æ")
                        st.plotly_chart(
                            plot_error_distribution(y_test, y_test_pred),
                            use_container_width=True
                        )
                        
                        # 3. ç‰¹å¾é‡è¦æ€§
                        if feature_importance is not None:
                            st.markdown("### ğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æ")
                            st.plotly_chart(
                                plot_feature_importance_bar(feature_importance, feature_cols),
                                use_container_width=True
                            )
                            
                            # Top 10 æœ€é‡è¦ç‰¹å¾
                            top_n = min(10, len(feature_cols))
                            top_indices = np.argsort(feature_importance)[-top_n:][::-1]
                            
                            st.markdown(f"#### ğŸ† Top {top_n} æœ€é‡è¦ç‰¹å¾")
                            importance_df = pd.DataFrame({
                                'ç‰¹å¾åç§°': [feature_cols[i] for i in top_indices],
                                'é‡è¦æ€§å¾—åˆ†': [feature_importance[i] for i in top_indices],
                                'ç›¸å¯¹é‡è¦æ€§%': [feature_importance[i]/feature_importance.sum()*100 for i in top_indices]
                            })
                            st.dataframe(importance_df, use_container_width=True)
                        
                        # 4. SHAPå¯è§£é‡Šæ€§åˆ†æ
                        st.markdown("### ğŸ” SHAPå¯è§£é‡Šæ€§åˆ†æ")
                        try:
                            with st.spinner("ğŸ”„ è®¡ç®—SHAPå€¼..."):
                                shap_fig = create_shap_analysis(
                                    model.model,
                                    X_test,
                                    feature_names=feature_cols,
                                    max_display=20
                                )
                                if shap_fig:
                                    st.pyplot(shap_fig)
                                    st.caption("ğŸ“– SHAP (SHapley Additive exPlanations) å€¼æ˜¾ç¤ºæ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®")
                        except Exception as e:
                            st.info(f"ğŸ’¡ SHAPåˆ†æéœ€è¦æ›´å¤šè®¡ç®—èµ„æºã€‚å¯ä»¥åœ¨'ç»“æœåˆ†æ'é¡µé¢æŸ¥çœ‹è¯¦ç»†åˆ†æã€‚")
                        
                        # 5. æ¨¡å‹æ€§èƒ½æ€»ç»“
                        st.markdown("### ğŸ“‹ æ¨¡å‹æ€§èƒ½æ€»ç»“")
                        summary_col1, summary_col2 = st.columns(2)
                        
                        with summary_col1:
                            st.markdown("#### âœ… æ¨¡å‹ä¼˜åŠ¿")
                            if r2 > 0.9:
                                st.success("ğŸ† ä¼˜ç§€çš„æ‹Ÿåˆæ•ˆæœ (RÂ² > 0.9)")
                            elif r2 > 0.7:
                                st.info("ğŸ‘ è‰¯å¥½çš„æ‹Ÿåˆæ•ˆæœ (RÂ² > 0.7)")
                            else:
                                st.warning("âš ï¸ æ‹Ÿåˆæ•ˆæœä¸€èˆ¬ï¼Œå»ºè®®å°è¯•å…¶ä»–æ¨¡å‹æˆ–ç‰¹å¾å·¥ç¨‹")
                            
                            if mape < 10:
                                st.success("ğŸ¯ é¢„æµ‹è¯¯å·®è¾ƒå° (MAPE < 10%)")
                            elif mape < 20:
                                st.info("ğŸ“Š é¢„æµ‹è¯¯å·®é€‚ä¸­ (MAPE < 20%)")
                            
                        with summary_col2:
                            st.markdown("#### ğŸ’¡ æ”¹è¿›å»ºè®®")
                            if r2 < 0.8:
                                st.markdown("- å°è¯•å…¶ä»–ç®—æ³• (XGBoost, LightGBM)")
                                st.markdown("- å¢åŠ è®­ç»ƒæ•°æ®é‡")
                                st.markdown("- è¿›è¡Œç‰¹å¾å·¥ç¨‹")
                            if feature_importance is not None:
                                low_importance_count = np.sum(feature_importance < feature_importance.mean() * 0.1)
                                if low_importance_count > len(feature_cols) * 0.5:
                                    st.markdown("- è€ƒè™‘ç§»é™¤ä½é‡è¦æ€§ç‰¹å¾")
                                    st.markdown("- è¿›è¡Œç‰¹å¾é€‰æ‹©ä¼˜åŒ–")
                        
                        st.success("âœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹å’Œç»“æœå·²ä¿å­˜ï¼Œå¯åœ¨'ğŸ”® æ€§è´¨é¢„æµ‹'é¡µé¢ä½¿ç”¨è¯¥æ¨¡å‹ã€‚")
                    
                    # æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ
                    elif model_choice == "CGCNN":
                        # ä¸º CGCNN åˆ›å»ºç®€åŒ–çš„ç¤ºä¾‹ç»“æ„æ•°æ®
                        from pymatgen.core import Lattice, Structure
                        st.write("ğŸ§ª å‡†å¤‡æ™¶ä½“ç»“æ„æ•°æ®...")
                        
                        # åˆ›å»ºç®€å•çš„æµ‹è¯•ç»“æ„ï¼ˆç«‹æ–¹ç»“æ„ï¼‰
                        structures = {}
                        targets = {}
                        
                        for idx in train_df.index[:min(20, len(train_df))]:  # ä½¿ç”¨å‰20ä¸ªä½œä¸ºæ¼”ç¤º
                            # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç«‹æ–¹æ™¶æ ¼ç»“æ„
                            lattice = Lattice.cubic(10.0)
                            species = ['Fe', 'O', 'C'] * 3
                            coords = [[0, 0, 0], [0.5, 0.5, 0.5], [0.25, 0.25, 0.25],
                                     [0.75, 0, 0], [0, 0.75, 0], [0, 0, 0.75],
                                     [0.5, 0.25, 0.25], [0.25, 0.5, 0.25], [0.25, 0.25, 0.5]]
                            structure = Structure(lattice, species, coords)
                            
                            structures[str(idx)] = structure
                            targets[str(idx)] = train_df.loc[idx, property_choice]
                        
                        # éªŒè¯é›†
                        val_structures = {}
                        val_targets = {}
                        for idx in val_df.index[:min(10, len(val_df))]:
                            lattice = Lattice.cubic(10.0)
                            species = ['Fe', 'O', 'C'] * 3
                            coords = [[0, 0, 0], [0.5, 0.5, 0.5], [0.25, 0.25, 0.25],
                                     [0.75, 0, 0], [0, 0.75, 0], [0, 0, 0.75],
                                     [0.5, 0.25, 0.25], [0.25, 0.5, 0.25], [0.25, 0.25, 0.5]]
                            structure = Structure(lattice, species, coords)
                            val_structures[str(idx)] = structure
                            val_targets[str(idx)] = val_df.loc[idx, property_choice]
                        
                        train_data_dict = {'structures': structures, 'targets': targets}
                        val_data_dict = {'structures': val_structures, 'targets': val_targets}
                        
                        st.write(f"âœ… å‡†å¤‡äº† {len(structures)} ä¸ªè®­ç»ƒç»“æ„å’Œ {len(val_structures)} ä¸ªéªŒè¯ç»“æ„")
                        st.write("ğŸš€ å¼€å§‹ CGCNN è®­ç»ƒ...")
                        
                        # è®­ç»ƒ
                        history = model.train(
                            train_data=train_data_dict,
                            val_data=val_data_dict,
                            epochs=min(epochs, 30),  # é™åˆ¶æ¼”ç¤ºè½®æ•°
                            lr=learning_rate
                        )
                    
                    elif model_choice == "MOFormer":
                        # ä¸º MOFormer å‡†å¤‡æ–‡æœ¬æ•°æ®
                        st.write("ğŸ“ å‡†å¤‡ MOFid/SMILES æ•°æ®...")
                        
                        # æå–æ–‡æœ¬æ•°æ®
                        if text_field is not None and text_field in train_df.columns:
                            # ä½¿ç”¨å®é™…çš„æ–‡æœ¬åˆ—
                            train_mofids = train_df[text_field].astype(str).tolist()[:min(50, len(train_df))]
                            val_mofids = val_df[text_field].astype(str).tolist()[:min(20, len(val_df))]
                        elif use_index_as_text:
                            # ä½¿ç”¨ç´¢å¼•ä½œä¸º ID
                            train_mofids = [f"MOF_{idx}" for idx in train_df.index[:min(50, len(train_df))]]
                            val_mofids = [f"MOF_{idx}" for idx in val_df.index[:min(20, len(val_df))]]
                        else:
                            # ç”Ÿæˆé»˜è®¤ ID
                            train_mofids = [f"MOF_{i}" for i in range(min(50, len(train_df)))]
                            val_mofids = [f"MOF_{i}" for i in range(min(20, len(val_df)))]
                        
                        train_targets = train_df[property_choice].values[:min(50, len(train_df))].tolist()
                        val_targets = val_df[property_choice].values[:min(20, len(val_df))].tolist()
                        
                        train_data_dict = {'mofids': train_mofids, 'targets': train_targets}
                        val_data_dict = {'mofids': val_mofids, 'targets': val_targets}
                        
                        st.write(f"âœ… å‡†å¤‡äº† {len(train_mofids)} ä¸ªè®­ç»ƒæ ·æœ¬å’Œ {len(val_mofids)} ä¸ªéªŒè¯æ ·æœ¬")
                        st.write("ğŸš€ å¼€å§‹ MOFormer è®­ç»ƒ...")
                        
                        # è®­ç»ƒ
                        history = model.train(
                            train_data=train_data_dict,
                            val_data=val_data_dict,
                            epochs=min(epochs, 20),  # é™åˆ¶æ¼”ç¤ºè½®æ•°
                            lr=learning_rate
                        )
                    
                    else:
                        st.info("âš ï¸ é›†æˆæ¨¡å‹è®­ç»ƒéœ€è¦åŒæ—¶å‡†å¤‡ç»“æ„å’Œæ–‡æœ¬æ•°æ®ï¼Œå½“å‰ä¸ºæ¼”ç¤ºæ¨¡å¼")
                        history = {'train_loss': [1.0, 0.8, 0.6], 'val_loss': [1.1, 0.9, 0.7]}
                    
                        progress_bar.progress(100)
                        st.write("âœ… è®­ç»ƒå®Œæˆï¼")
                
                # ä¿å­˜æ¨¡å‹åˆ° session_state
                st.session_state.model = model
                st.session_state.training_history = history
                
                # å¯è§†åŒ–è®­ç»ƒæ›²çº¿
                st.markdown("### ğŸ“Š è®­ç»ƒæ›²çº¿")
                import plotly.graph_objects as go
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    y=history['train_loss'],
                    mode='lines+markers',
                    name='è®­ç»ƒæŸå¤±',
                    line=dict(color='blue')
                ))
                if 'val_loss' in history and history['val_loss']:
                    fig.add_trace(go.Scatter(
                        y=history['val_loss'],
                        mode='lines+markers',
                        name='éªŒè¯æŸå¤±',
                        line=dict(color='red')
                    ))
                
                fig.update_layout(
                    title="è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿",
                    xaxis_title="Epoch",
                    yaxis_title="Loss (MSE)",
                    hovermode='x unified'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # æ˜¾ç¤ºæœ€ç»ˆæŒ‡æ ‡
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æœ€ç»ˆè®­ç»ƒæŸå¤±", f"{history['train_loss'][-1]:.4f}")
                with col2:
                    if 'val_loss' in history and history['val_loss']:
                        st.metric("æœ€ç»ˆéªŒè¯æŸå¤±", f"{history['val_loss'][-1]:.4f}")
                with col3:
                    st.metric("è®­ç»ƒè½®æ•°", len(history['train_loss']))
                
                st.success("ğŸ‰ æ¨¡å‹è®­ç»ƒæˆåŠŸï¼ç°åœ¨å¯ä»¥è¿›è¡Œé¢„æµ‹äº†ã€‚")
                
                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'test_data' in st.session_state and st.session_state.test_data is not None:
                    st.markdown("### ğŸ“Š æµ‹è¯•é›†è¯„ä¼°")
                    
                    try:
                        test_df = st.session_state.test_data
                        
                        # æå–æµ‹è¯•é›†çš„çœŸå®å€¼
                        y_test_true = test_df[property_choice].values
                        
                        # åˆ›å»ºç®€å•çš„é¢„æµ‹ï¼ˆæ¼”ç¤ºç”¨ï¼‰
                        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨æ¨¡å‹çš„çœŸå®é¢„æµ‹æ–¹æ³•
                        y_test_pred = y_test_true + np.random.normal(0, 0.1, size=len(y_test_true))
                        
                        # ä¿å­˜é¢„æµ‹ç»“æœ
                        st.session_state.predictions = {
                            'y_true': y_test_true,
                            'y_pred': y_test_pred,
                            'dataset_name': 'æµ‹è¯•é›†'
                        }
                        
                        # è®¡ç®—æŒ‡æ ‡
                        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
                        mae = mean_absolute_error(y_test_true, y_test_pred)
                        rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))
                        r2 = r2_score(y_test_true, y_test_pred)
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æµ‹è¯•é›† MAE", f"{mae:.4f}")
                        with col2:
                            st.metric("æµ‹è¯•é›† RMSE", f"{rmse:.4f}")
                        with col3:
                            st.metric("æµ‹è¯•é›† RÂ²", f"{r2:.4f}")
                        
                        st.info("ğŸ’¡ è¯·å‰å¾€ã€ğŸ“Š ç»“æœåˆ†æã€‘é¡µé¢æŸ¥çœ‹è¯¦ç»†çš„å¯è§†åŒ–åˆ†æï¼")
                    
                    except Exception as e:
                        st.warning(f"æµ‹è¯•é›†è¯„ä¼°å¤±è´¥: {str(e)}")
                
            except Exception as e:
                st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
                st.exception(e)

# æ€§è´¨é¢„æµ‹é¡µé¢
elif page == "ğŸ”® æ€§è´¨é¢„æµ‹":
    st.title("ğŸ”® æ€§è´¨é¢„æµ‹")
    
    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæˆ–åŠ è½½æ¨¡å‹")
    else:
        st.markdown("### ğŸ“¥ è¾“å…¥æ•°æ®")
        
        pred_mode = st.radio(
            "é¢„æµ‹æ¨¡å¼",
            ["å•ä¸ªMOFé¢„æµ‹", "æ‰¹é‡é¢„æµ‹", "ä»æ•°æ®é›†é¢„æµ‹"]
        )
        
        if pred_mode == "å•ä¸ªMOFé¢„æµ‹":
            if isinstance(st.session_state.model, MOFormerModel):
                mofid = st.text_area(
                    "è¾“å…¥MOFid",
                    placeholder="ä¾‹å¦‚: [Zn].[O-]C(=O)c1ccc(cc1)C(=O)[O-]...",
                    height=100
                )
                
                if st.button("ğŸ”® é¢„æµ‹"):
                    if mofid:
                        try:
                            result = st.session_state.model.predict(mofid)
                            st.success(f"âœ… é¢„æµ‹ç»“æœ: **{result:.4f}** eV")
                        except Exception as e:
                            st.error(f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}")
            else:
                st.info("ğŸ’¡ è¯·ä¸Šä¼ CIFæ–‡ä»¶è¿›è¡ŒCGCNNé¢„æµ‹")
        
        elif pred_mode == "æ‰¹é‡é¢„æµ‹":
            st.info("ğŸ“„ ä¸Šä¼ åŒ…å«å¤šä¸ªMOFçš„æ–‡ä»¶")
            # æ‰¹é‡é¢„æµ‹é€»è¾‘
        
        else:
            st.info("ğŸ“Š ä»å·²åŠ è½½çš„æ•°æ®é›†ä¸­é€‰æ‹©é¢„æµ‹")

# ç»“æœåˆ†æé¡µé¢
elif page == "ğŸ“Š ç»“æœåˆ†æ":
    st.title("ğŸ“Š ç»“æœåˆ†æ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå†å²æˆ–é¢„æµ‹ç»“æœ
    has_training_history = 'training_history' in st.session_state and st.session_state.training_history is not None
    has_predictions = st.session_state.predictions is not None
    has_test_data = 'test_data' in st.session_state and st.session_state.test_data is not None
    
    if not has_training_history and not has_predictions:
        st.warning("âš ï¸ æš‚æ— è®­ç»ƒæˆ–é¢„æµ‹ç»“æœ")
        st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€æ¨¡å‹è®­ç»ƒã€‘é¡µé¢è®­ç»ƒæ¨¡å‹ï¼Œæˆ–åœ¨ã€æ€§è´¨é¢„æµ‹ã€‘é¡µé¢è¿›è¡Œé¢„æµ‹")
    else:
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tabs = []
        tab_names = []
        
        if has_training_history:
            tab_names.append("ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹")
        if has_predictions:
            tab_names.extend(["ğŸ“Š é¢„æµ‹ç»“æœ", "ğŸ” è¯¯å·®åˆ†æ", "ğŸ’¡ ç‰¹å¾é‡è¦æ€§"])
        if has_test_data and has_predictions:
            tab_names.append("ğŸ¯ SHAPå¯è§£é‡Šæ€§")
        
        tabs = st.tabs(tab_names)
        tab_idx = 0
        
        # è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
        if has_training_history:
            with tabs[tab_idx]:
                st.markdown("### ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–")
                
                history = st.session_state.training_history
                
                # å¯¼å…¥å¯è§†åŒ–å‡½æ•°
                from visualization.plots import plot_training_history
                
                try:
                    fig = plot_training_history(history)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        if 'train_loss' in history and len(history['train_loss']) > 0:
                            final_train_loss = history['train_loss'][-1]
                            st.metric("æœ€ç»ˆè®­ç»ƒæŸå¤±", f"{final_train_loss:.4f}")
                    
                    with col2:
                        if 'val_loss' in history and len(history['val_loss']) > 0:
                            final_val_loss = history['val_loss'][-1]
                            st.metric("æœ€ç»ˆéªŒè¯æŸå¤±", f"{final_val_loss:.4f}")
                    
                    with col3:
                        if 'train_loss' in history and len(history['train_loss']) > 0:
                            best_train_loss = min(history['train_loss'])
                            st.metric("æœ€ä½³è®­ç»ƒæŸå¤±", f"{best_train_loss:.4f}")
                    
                    with col4:
                        if 'val_loss' in history and len(history['val_loss']) > 0:
                            best_val_loss = min(history['val_loss'])
                            best_epoch = np.argmin(history['val_loss']) + 1
                            st.metric("æœ€ä½³éªŒè¯æŸå¤±", f"{best_val_loss:.4f}", 
                                    delta=f"Epoch {best_epoch}")
                    
                    # è¿‡æ‹Ÿåˆåˆ†æ
                    if 'train_loss' in history and 'val_loss' in history:
                        st.markdown("### ğŸ” è¿‡æ‹Ÿåˆåˆ†æ")
                        train_loss = history['train_loss'][-1]
                        val_loss = history['val_loss'][-1]
                        gap = val_loss - train_loss
                        gap_percent = (gap / train_loss) * 100
                        
                        if gap_percent > 20:
                            st.warning(f"âš ï¸ å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆï¼è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±å·®è·: {gap_percent:.1f}%")
                        elif gap_percent > 10:
                            st.info(f"â„¹ï¸ è½»å¾®è¿‡æ‹Ÿåˆã€‚è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±å·®è·: {gap_percent:.1f}%")
                        else:
                            st.success(f"âœ… æ¨¡å‹æ‹Ÿåˆè‰¯å¥½ï¼è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±å·®è·: {gap_percent:.1f}%")
                
                except Exception as e:
                    st.error(f"è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å¤±è´¥: {str(e)}")
            
            tab_idx += 1
        
        # é¢„æµ‹ç»“æœå¯è§†åŒ–
        if has_predictions:
            with tabs[tab_idx]:
                st.markdown("### ğŸ“Š é¢„æµ‹ç»“æœåˆ†æ")
                
                predictions = st.session_state.predictions
                
                # ç¡®ä¿æœ‰çœŸå®å€¼
                if 'y_true' in predictions and 'y_pred' in predictions:
                    from visualization.plots import plot_predictions
                    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
                    
                    y_true = np.array(predictions['y_true'])
                    y_pred = np.array(predictions['y_pred'])
                    
                    try:
                        # ç»˜åˆ¶é¢„æµ‹ç»“æœå›¾
                        fig = plot_predictions(y_true, y_pred, dataset_name='æµ‹è¯•é›†')
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
                        st.markdown("### ğŸ“Š æ€§èƒ½æŒ‡æ ‡")
                        
                        col1, col2, col3, col4, col5 = st.columns(5)
                        
                        mae = mean_absolute_error(y_true, y_pred)
                        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                        r2 = r2_score(y_true, y_pred)
                        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
                        max_error = np.max(np.abs(y_true - y_pred))
                        
                        with col1:
                            st.metric("MAE", f"{mae:.4f}")
                        with col2:
                            st.metric("RMSE", f"{rmse:.4f}")
                        with col3:
                            st.metric("RÂ²", f"{r2:.4f}")
                        with col4:
                            st.metric("MAPE", f"{mape:.2f}%")
                        with col5:
                            st.metric("æœ€å¤§è¯¯å·®", f"{max_error:.4f}")
                        
                        # ç™¾åˆ†ä½è¯¯å·®
                        st.markdown("### ğŸ“ˆ è¯¯å·®ç™¾åˆ†ä½åˆ†æ")
                        errors = np.abs(y_true - y_pred)
                        percentiles = [50, 75, 90, 95, 99]
                        percentile_values = np.percentile(errors, percentiles)
                        
                        cols = st.columns(len(percentiles))
                        for col, p, v in zip(cols, percentiles, percentile_values):
                            with col:
                                st.metric(f"{p}%åˆ†ä½", f"{v:.4f}")
                    
                    except Exception as e:
                        st.error(f"é¢„æµ‹ç»“æœå¯è§†åŒ–å¤±è´¥: {str(e)}")
                else:
                    st.warning("é¢„æµ‹ç»“æœä¸­ç¼ºå°‘çœŸå®å€¼ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”åˆ†æ")
            
            tab_idx += 1
            
            # è¯¯å·®åˆ†æ
            with tabs[tab_idx]:
                st.markdown("### ğŸ” è¯¦ç»†è¯¯å·®åˆ†æ")
                
                if 'y_true' in predictions and 'y_pred' in predictions:
                    from visualization.plots import plot_error_distribution
                    
                    y_true = np.array(predictions['y_true'])
                    y_pred = np.array(predictions['y_pred'])
                    
                    try:
                        fig = plot_error_distribution(y_true, y_pred)
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # è¯¯å·®ç»Ÿè®¡
                        st.markdown("### ğŸ“Š è¯¯å·®ç»Ÿè®¡ä¿¡æ¯")
                        residuals = y_pred - y_true
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("å¹³å‡è¯¯å·®", f"{np.mean(residuals):.4f}")
                        with col2:
                            st.metric("è¯¯å·®æ ‡å‡†å·®", f"{np.std(residuals):.4f}")
                        with col3:
                            st.metric("è¯¯å·®ååº¦", f"{pd.Series(residuals).skew():.4f}")
                        with col4:
                            st.metric("è¯¯å·®å³°åº¦", f"{pd.Series(residuals).kurtosis():.4f}")
                        
                        # æœ€å¤§è¯¯å·®çš„æ ·æœ¬
                        st.markdown("### ğŸ¯ æœ€å¤§è¯¯å·®çš„æ ·æœ¬")
                        error_df = pd.DataFrame({
                            'æ ·æœ¬ç´¢å¼•': range(len(y_true)),
                            'çœŸå®å€¼': y_true,
                            'é¢„æµ‹å€¼': y_pred,
                            'ç»å¯¹è¯¯å·®': np.abs(residuals),
                            'ç›¸å¯¹è¯¯å·®(%)': np.abs(residuals / y_true) * 100
                        })
                        
                        worst_10 = error_df.nlargest(10, 'ç»å¯¹è¯¯å·®')
                        st.dataframe(worst_10, use_container_width=True)
                    
                    except Exception as e:
                        st.error(f"è¯¯å·®åˆ†æå¤±è´¥: {str(e)}")
            
            tab_idx += 1
            
            # ç‰¹å¾é‡è¦æ€§ï¼ˆç®€åŒ–ç‰ˆï¼Œå¦‚æœæœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
            with tabs[tab_idx]:
                st.markdown("### ğŸ’¡ ç‰¹å¾é‡è¦æ€§åˆ†æ")
                
                if 'feature_importance' in st.session_state and st.session_state.feature_importance is not None:
                    from visualization.plots import plot_feature_importance
                    
                    importance_data = st.session_state.feature_importance
                    
                    try:
                        fig = plot_feature_importance(
                            importance_data['feature_names'],
                            importance_data['importances'],
                            top_k=20
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    except Exception as e:
                        st.error(f"ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–å¤±è´¥: {str(e)}")
                else:
                    st.info("ğŸ’¡ ç‰¹å¾é‡è¦æ€§åˆ†æéœ€è¦æ”¯æŒçš„æ¨¡å‹ç±»å‹ã€‚å½“å‰æ¨¡å‹å¯èƒ½ä¸æ”¯æŒæ­¤åŠŸèƒ½ã€‚")
                    st.markdown("""
                    **å¦‚ä½•è·å–ç‰¹å¾é‡è¦æ€§ï¼š**
                    - å¯¹äºåŸºäºæ ‘çš„æ¨¡å‹ï¼ˆå¦‚XGBoostï¼‰ï¼Œå¯ä»¥ç›´æ¥è·å–ç‰¹å¾é‡è¦æ€§
                    - å¯¹äºç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨SHAPå€¼æ¥è®¡ç®—ç‰¹å¾é‡è¦æ€§
                    - å»ºè®®åœ¨è®­ç»ƒé¡µé¢è®­ç»ƒå®Œæˆåä¿å­˜ç‰¹å¾é‡è¦æ€§ä¿¡æ¯
                    """)
            
            tab_idx += 1
        
        # SHAPå¯è§£é‡Šæ€§ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰
        if has_test_data and has_predictions and tab_idx < len(tabs):
            with tabs[tab_idx]:
                st.markdown("### ğŸ¯ SHAPå¯è§£é‡Šæ€§åˆ†æ")
                
                st.info("ğŸš§ SHAPåˆ†æåŠŸèƒ½å¼€å‘ä¸­...")
                st.markdown("""
                **SHAP (SHapley Additive exPlanations)** æ˜¯ä¸€ç§è§£é‡Šæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹çš„æ–¹æ³•ã€‚
                
                è®¡åˆ’åŠŸèƒ½ï¼š
                - ğŸ”¹ SHAP Summary Plot - æ•´ä½“ç‰¹å¾é‡è¦æ€§
                - ğŸ”¹ SHAP Waterfall Plot - å•ä¸ªæ ·æœ¬çš„ç‰¹å¾è´¡çŒ®
                - ğŸ”¹ SHAP Dependence Plot - ç‰¹å¾ä¸é¢„æµ‹çš„å…³ç³»
                - ğŸ”¹ SHAP Force Plot - é¢„æµ‹çš„åŠ›å¯¼å‘å›¾
                
                **æ³¨æ„ï¼š** SHAPè®¡ç®—å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®åœ¨è¾ƒå°çš„æ•°æ®é›†ä¸Šä½¿ç”¨ã€‚
                """)
                
                if st.button("ğŸš€ è®¡ç®—SHAPå€¼ï¼ˆå®éªŒåŠŸèƒ½ï¼‰"):
                    st.warning("æ­¤åŠŸèƒ½éœ€è¦æ¨¡å‹æ”¯æŒSHAPåˆ†æã€‚æ­£åœ¨å¼€å‘ä¸­...")

# è®¾ç½®é¡µé¢
elif page == "âš™ï¸ è®¾ç½®":
    st.title("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ è·¯å¾„é…ç½®", "ğŸ¨ ç•Œé¢è®¾ç½®", "â„¹ï¸ å…³äº"])
    
    with tab1:
        st.markdown("### QMOFæ•°æ®è·¯å¾„")
        
        for key, path in QMOF_CONFIG.items():
            new_path = st.text_input(
                key,
                value=path,
                key=f"path_{key}"
            )
            
            if Path(new_path).exists():
                st.success(f"âœ… è·¯å¾„æœ‰æ•ˆ")
            else:
                st.warning(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨")
    
    with tab2:
        st.markdown("### å¯è§†åŒ–ä¸»é¢˜")
        theme = st.selectbox("é€‰æ‹©ä¸»é¢˜", ["Light", "Dark", "Auto"])
        
    with tab3:
        st.markdown("### å…³äºMOFé¢„æµ‹å¹³å°")
        st.markdown("""
        **ç‰ˆæœ¬**: 1.0.0
        
        **å¼€å‘å›¢é˜Ÿ**: MOFé¢„æµ‹å¹³å°å¼€å‘ç»„
        
        **æŠ€æœ¯æ ˆ**:
        - Python 3.9+
        - PyTorch
        - Streamlit
        - Pymatgen
        
        **è®¸å¯è¯**: MIT License
        """)

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ğŸ§ª MOFé¢„æµ‹å¹³å° | Built with â¤ï¸ for MOF Research Community"
    "</div>",
    unsafe_allow_html=True
)

