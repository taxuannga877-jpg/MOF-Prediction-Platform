# å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

## å®Œæ•´çš„ä½¿ç”¨æµç¨‹ç¤ºä¾‹

### ç¤ºä¾‹1: ä½¿ç”¨CGCNNé¢„æµ‹èƒ½å¸¦éš™

```python
from src.models import CGCNNModel
from src.utils import DataLoader, DataProcessor
from src.config import QMOF_CONFIG, CGCNN_CONFIG

# 1. åŠ è½½QMOFæ•°æ®
print("ğŸ“¥ åŠ è½½QMOFæ•°æ®...")
data_loader = DataLoader(QMOF_CONFIG)

# åŠ è½½ç»“æ„æ•°æ®
structures, _ = data_loader.load_qmof_data('structures', limit=1000)

# åŠ è½½å±æ€§æ•°æ®
properties_data, _ = data_loader.load_qmof_data('json', limit=1000)

# 2. æå–ç›®æ ‡å±æ€§
print("ğŸ“Š æå–èƒ½å¸¦éš™æ•°æ®...")
data_processor = DataProcessor()
mof_ids, bandgaps = data_processor.extract_property_from_qmof(
    properties_data,
    property_name='bandgap',
    theory_level='pbe'
)

# æ„å»ºè®­ç»ƒæ•°æ®
targets = {mof_id: bg for mof_id, bg in zip(mof_ids, bandgaps)}

# 3. åˆ’åˆ†æ•°æ®é›†
from sklearn.model_selection import train_test_split

train_ids, test_ids = train_test_split(mof_ids, test_size=0.2, random_state=42)
train_ids, val_ids = train_test_split(train_ids, test_size=0.125, random_state=42)

train_data = {
    'structures': {mid: structures[mid] for mid in train_ids if mid in structures},
    'targets': {mid: targets[mid] for mid in train_ids if mid in targets}
}

val_data = {
    'structures': {mid: structures[mid] for mid in val_ids if mid in structures},
    'targets': {mid: targets[mid] for mid in val_ids if mid in targets}
}

test_data = {
    'structures': {mid: structures[mid] for mid in test_ids if mid in structures},
    'targets': {mid: targets[mid] for mid in test_ids if mid in targets}
}

# 4. åˆ›å»ºå’Œè®­ç»ƒCGCNNæ¨¡å‹
print("ğŸ¤– åˆ›å»ºCGCNNæ¨¡å‹...")
config = CGCNN_CONFIG.copy()
config.update({
    'batch_size': 32,
    'epochs': 100,
    'lr': 0.001
})

model = CGCNNModel(config)
model.build_model()

# 5. è®­ç»ƒæ¨¡å‹
print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
history = model.train(train_data, val_data, epochs=100)

# 6. è¯„ä¼°æ¨¡å‹
print("ğŸ“Š è¯„ä¼°æ¨¡å‹...")
test_targets = list(test_data['targets'].values())
metrics = model.evaluate(test_data['structures'], test_targets)

print(f"âœ… æµ‹è¯•é›†æ€§èƒ½:")
print(f"   MAE: {metrics['mae']:.4f} eV")
print(f"   RMSE: {metrics['rmse']:.4f} eV")
print(f"   RÂ²: {metrics['r2']:.4f}")

# 7. ä¿å­˜æ¨¡å‹
print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
model.save_model('models/saved_models/cgcnn_bandgap.pth')

# 8. é¢„æµ‹æ–°MOF
print("ğŸ”® é¢„æµ‹æ–°MOF...")
new_mof_ids = list(test_data['structures'].keys())[:5]
new_structures = {mid: test_data['structures'][mid] for mid in new_mof_ids}

predictions = model.predict(new_structures)

print("é¢„æµ‹ç»“æœ:")
for mof_id, pred in predictions.items():
    true_val = test_data['targets'][mof_id]
    print(f"  {mof_id}: é¢„æµ‹={pred:.3f} eV, çœŸå®={true_val:.3f} eV")
```

### ç¤ºä¾‹2: ä½¿ç”¨MOFormeré¢„æµ‹èƒ½å¸¦éš™

```python
from src.models import MOFormerModel
from src.utils import DataLoader, DataProcessor
from src.config import QMOF_CONFIG, MOFORMER_CONFIG

# 1. åŠ è½½QMOFæ•°æ®
print("ğŸ“¥ åŠ è½½QMOFæ•°æ®...")
data_loader = DataLoader(QMOF_CONFIG)
properties_data, _ = data_loader.load_qmof_data('json', limit=5000)

# 2. å‡†å¤‡MOFormeræ•°æ®
print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
data_processor = DataProcessor()
mofids, targets = data_processor.prepare_for_moformer(
    properties_data,
    target_property='bandgap'
)

# 3. åˆ’åˆ†æ•°æ®é›†
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    mofids, targets, test_size=0.2, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.125, random_state=42
)

train_data = {'mofids': X_train, 'targets': y_train}
val_data = {'mofids': X_val, 'targets': y_val}

# 4. åˆ›å»ºå’Œè®­ç»ƒMOFormer
print("ğŸ¤– åˆ›å»ºMOFormeræ¨¡å‹...")
config = MOFORMER_CONFIG.copy()
config.update({
    'batch_size': 16,
    'lr': 1e-4,
    'd_model': 256,
    'num_layers': 6
})

model = MOFormerModel(config)
model.build_model()

# 5. è®­ç»ƒ
print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
history = model.train(train_data, val_data, epochs=50)

# 6. è¯„ä¼°
print("ğŸ“Š è¯„ä¼°æ¨¡å‹...")
test_predictions = model.predict(X_test)
metrics = model.evaluate(X_test, y_test)

print(f"âœ… æµ‹è¯•é›†æ€§èƒ½:")
print(f"   MAE: {metrics['mae']:.4f} eV")
print(f"   RMSE: {metrics['rmse']:.4f} eV")
print(f"   RÂ²: {metrics['r2']:.4f}")

# 7. å•ä¸ªé¢„æµ‹
print("\nğŸ”® å•ä¸ªMOFé¢„æµ‹:")
single_mofid = X_test[0]
single_pred = model.predict(single_mofid)
print(f"MOFid: {single_mofid[:50]}...")
print(f"é¢„æµ‹èƒ½å¸¦éš™: {single_pred:.3f} eV")
print(f"çœŸå®èƒ½å¸¦éš™: {y_test[0]:.3f} eV")

# 8. ä¿å­˜æ¨¡å‹
model.save_model('models/saved_models/moformer_bandgap.pth')
```

### ç¤ºä¾‹3: ä½¿ç”¨é›†æˆæ¨¡å‹

```python
from src.models import EnsembleModel
from src.utils import DataLoader, DataProcessor
from src.config import QMOF_CONFIG, ENSEMBLE_CONFIG

# 1. åŠ è½½å®Œæ•´æ•°æ®ï¼ˆç»“æ„ + MOFidï¼‰
print("ğŸ“¥ åŠ è½½QMOFå®Œæ•´æ•°æ®...")
data_loader = DataLoader(QMOF_CONFIG)

# åŠ è½½ç»“æ„
structures, _ = data_loader.load_qmof_data('structures', limit=1000)

# åŠ è½½å±æ€§
properties_data, _ = data_loader.load_qmof_data('json', limit=1000)

# 2. å‡†å¤‡æ•°æ®
print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
data_processor = DataProcessor()

# æå–MOFid
mofids, targets = data_processor.prepare_for_moformer(
    properties_data,
    target_property='bandgap'
)

# æ„å»ºç›®æ ‡å­—å…¸
targets_dict = {f"mof_{i}": t for i, t in enumerate(targets)}

# 3. å‡†å¤‡é›†æˆæ¨¡å‹æ•°æ®
train_data = {
    'structures': structures,  # for CGCNN
    'mofids': mofids,         # for MOFormer
    'targets': targets        # å…±åŒçš„ç›®æ ‡
}

# 4. åˆ›å»ºé›†æˆæ¨¡å‹
print("ğŸ¤– åˆ›å»ºé›†æˆæ¨¡å‹...")
config = ENSEMBLE_CONFIG.copy()
config.update({
    'cgcnn_weight': 0.6,
    'moformer_weight': 0.4,
    'ensemble_method': 'weighted'
})

model = EnsembleModel(config)
model.build_model()

# 5. è®­ç»ƒï¼ˆä¼šåˆ†åˆ«è®­ç»ƒCGCNNå’ŒMOFormerï¼‰
print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
history = model.train(train_data, epochs=100)

# 6. é¢„æµ‹ï¼ˆè‡ªåŠ¨ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹ï¼‰
print("ğŸ”® é›†æˆé¢„æµ‹...")
test_data = {
    'structures': structures,
    'mofids': mofids
}

predictions = model.predict(test_data)

# 7. è¯„ä¼°
metrics = model.evaluate(test_data, targets)

print("âœ… é›†æˆæ¨¡å‹æ€§èƒ½:")
for model_name, model_metrics in metrics.items():
    print(f"\n{model_name.upper()}:")
    print(f"  MAE: {model_metrics['mae']:.4f} eV")
    print(f"  RMSE: {model_metrics['rmse']:.4f} eV")
    print(f"  RÂ²: {model_metrics['r2']:.4f}")

# 8. ä¿å­˜é›†æˆæ¨¡å‹
model.save_model('models/saved_models/ensemble_model/')
```

### ç¤ºä¾‹4: ä½¿ç”¨Streamlitç•Œé¢

```bash
# 1. å¯åŠ¨å¹³å°
bash scripts/run_platform.sh

# 2. æ‰“å¼€æµè§ˆå™¨è®¿é—®
# http://localhost:8501

# 3. åœ¨ç•Œé¢ä¸­æ“ä½œï¼š
# - æ•°æ®ç®¡ç† â†’ åŠ è½½QMOFæ•°æ®
# - æ¨¡å‹è®­ç»ƒ â†’ é€‰æ‹©æ¨¡å‹ â†’ è®¾ç½®å‚æ•° â†’ å¼€å§‹è®­ç»ƒ
# - æ€§è´¨é¢„æµ‹ â†’ è¾“å…¥MOF â†’ è·å¾—é¢„æµ‹
# - ç»“æœåˆ†æ â†’ æŸ¥çœ‹å¯è§†åŒ–å’Œè§£é‡Š
```

### ç¤ºä¾‹5: å‘½ä»¤è¡Œæ‰¹é‡é¢„æµ‹

```python
# batch_predict.py
import sys
from pathlib import Path
from src.models import CGCNNModel
from src.utils import FileHandler
import pandas as pd

# åŠ è½½æ¨¡å‹
model = CGCNNModel()
model.load_model('models/saved_models/cgcnn_bandgap.pth')

# åŠ è½½CIFæ–‡ä»¶
cif_dir = Path(sys.argv[1])  # ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç›®å½•
file_handler = FileHandler()

structures = {}
for cif_file in cif_dir.glob('*.cif'):
    try:
        structure = file_handler.read_cif(cif_file)
        structures[cif_file.stem] = structure
    except Exception as e:
        print(f"è­¦å‘Š: æ— æ³•è¯»å– {cif_file}: {e}")

# æ‰¹é‡é¢„æµ‹
print(f"ğŸ”® é¢„æµ‹ {len(structures)} ä¸ªMOF...")
predictions = model.predict(structures)

# ä¿å­˜ç»“æœ
results = pd.DataFrame([
    {'mof_id': mof_id, 'predicted_bandgap': pred}
    for mof_id, pred in predictions.items()
])

output_file = 'predictions_results.csv'
results.to_csv(output_file, index=False)

print(f"âœ… é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {output_file}")
print(results.describe())
```

ä½¿ç”¨æ–¹æ³•ï¼š
```bash
python batch_predict.py /path/to/cif/directory/
```

## æ€§èƒ½åŸºå‡†

### QMOFèƒ½å¸¦éš™é¢„æµ‹ï¼ˆ10,000ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰

| æ¨¡å‹ | MAE (eV) | RMSE (eV) | RÂ² | è®­ç»ƒæ—¶é—´ | æ¨ç†æ—¶é—´/æ ·æœ¬ |
|------|----------|-----------|-----|----------|-------------|
| CGCNN | 0.270 | 0.485 | 0.89 | ~4å°æ—¶ | ~50ms |
| MOFormer | 0.320 | 0.520 | 0.86 | ~2å°æ—¶ | ~10ms |
| é›†æˆæ¨¡å‹ | 0.245 | 0.450 | 0.91 | ~6å°æ—¶ | ~60ms |

*ç¡¬ä»¶: NVIDIA RTX 3090, 24GBæ˜¾å­˜*

## æ•…éšœæ’é™¤

### é—®é¢˜1: CUDAå†…å­˜ä¸è¶³

```python
# è§£å†³æ–¹æ¡ˆ1: å‡å°batch size
config['batch_size'] = 16  # ä»32é™åˆ°16

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨CPU
import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # ç¦ç”¨GPU

# è§£å†³æ–¹æ¡ˆ3: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
# åœ¨è®­ç»ƒå¾ªç¯ä¸­å®ç°
```

### é—®é¢˜2: æ•°æ®åŠ è½½å¤ªæ…¢

```python
# è§£å†³æ–¹æ¡ˆ: é™åˆ¶åŠ è½½æ•°é‡
data, _ = data_loader.load_qmof_data('structures', limit=100)

# æˆ–è€…é¢„å…ˆå¤„ç†æ•°æ®
# å°†å¤§çš„JSONæ–‡ä»¶åˆ†å‰²æˆå°æ–‡ä»¶
```

### é—®é¢˜3: æ¨¡å‹ä¸æ”¶æ•›

```python
# è§£å†³æ–¹æ¡ˆ1: è°ƒæ•´å­¦ä¹ ç‡
config['lr'] = 1e-4  # é™ä½å­¦ä¹ ç‡

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨
from torch.optim.lr_scheduler import ReduceLROnPlateau
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)

# è§£å†³æ–¹æ¡ˆ3: å¢åŠ æ­£åˆ™åŒ–
config['weight_decay'] = 1e-4
```

## ä¸‹ä¸€æ­¥

- é˜…è¯»[å®Œæ•´ç”¨æˆ·æŒ‡å—](user_guide.md)
- æŸ¥çœ‹[APIæ–‡æ¡£](api_reference.md)
- å‚è€ƒ[æ¨¡å‹è¯¦è§£](model_details.md)
- æµè§ˆ[ç¤ºä¾‹æ•™ç¨‹](examples/)


